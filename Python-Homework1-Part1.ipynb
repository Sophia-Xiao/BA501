{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q1: How do you handle duplicate values in a dataset in Python?\n",
    "\n",
    "list(set(my_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q2: You are given two tables - friend_request and request_accepted. \n",
    "#Friend_request contains requester_id, time and sent_to_id \n",
    "#and request_accepted table contains time, acceptor_id and requestor_id. \n",
    "#How will you determine the overall acceptance rate of requests? \n",
    "\n",
    "# Solution-1:  Use SQL\n",
    "\n",
    "select\n",
    "t.count(*) as total_request\n",
    ",sum(accepted_flag) as total_accepted\n",
    ",sum(accepted_flag) / t.count(*) as acceptance_rate\n",
    "(\n",
    "r.requester_id\n",
    ",a.acceptor_id\n",
    ",case when a.acceptor_id is not null then 1 else 0 end as accepted_flag\n",
    "from friend_request r\n",
    "left join\n",
    "request_accepted a\n",
    "on r.requester_id = a.requestor_id\n",
    "and r.sent_to_id = a.acceptor_id\n",
    "group by 1,2\n",
    ") t\n",
    "\n",
    "# Solution-2:  Use Python\n",
    "import pandas as pd\n",
    "\n",
    "new_data = pd.merge(friend_request, request_accepted, on=[\"requester_id\", \"sent_to_id\"], how=\"left\")\n",
    "\n",
    "def f(row):\n",
    "    if row['accepted_id'] == '':\n",
    "        val = 0\n",
    "    else:\n",
    "        val = 1\n",
    "    return val\n",
    "\n",
    "new_data['accepted_flag'] = new_data.apply(f, axis=1)\n",
    "\n",
    "accepted_rate = new_data.groupby([\"requester_id\", \"sent_to_id\"])[\"accepted_flag\"].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Q4: \n",
    "\n",
    "def PrintCumulativeTimeSeries(my_data, experiment_ids):\n",
    "    # make sure our x-axis is consistent\n",
    "    date_series = my_data.date\n",
    "    index_series = np.unique(date_series) # unique date\n",
    "    index_series = np.sort(index_series) # sort by date\n",
    "    \n",
    "    # data grouping\n",
    "    my_data = my_data.sort_values(\"date\", ascending=True, inplace=False)\n",
    "    treatment_series = np.cumsum(GetSeries(my_data, experiment_ids[0]))\n",
    "    control_series = np.cumsum(GetSeries(my_data, experiment_ids[1]))\n",
    "    uplift_series = (treatment_series - control_series)/control_series*100\n",
    "    \n",
    "    PlotSeries(index_series, treatment_series, control_series, uplift_series)\n",
    "    \n",
    "PrintCumulativeTimeSeries(my_data, [12624548,12624549])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
